{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#CA3532\"><h1 align=\"left\">Fundamentos de Análisis de Datos</h1></font>\n",
    "<font color=\"#6E6E6E\"><h2 align=\"left\">Preprocesado de Datos con Python</h2></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#CA3532\">2. Limpieza de datos</font>\n",
    "\n",
    "La siguiente etapa del preprocesado es la limpieza de datos, que consiste en las siguientes tareas (entre otras):\n",
    "\n",
    "- Tratamiento de valores ausentes (detección, filtrado, imputación)\n",
    "- Tratamiento de ouliers (o \"valores atípicos\")\n",
    "- Eliminación de información irrelevante (por ejemplo, atributos constantes)\n",
    "- Detección y eliminación de patrones duplicados\n",
    "- Eliminación y/o arreglo de inconsistencias en los datos\n",
    "\n",
    "Primero importaremos las librerías que necesitaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Eliminación de missing values</font>\n",
    "\n",
    "Primero empezaremos con la base de datos \"small.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos:\n",
    "data = pd.read_csv(\"datasets/small.csv\", na_values = [\"?\", \"none\"], sep = \",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0] # número de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of missing values:\n",
    "100*data.isnull().sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar missing values usaremos el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html#pandas-dataframe-dropna\">pandas.DataFrame.dropna</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar todas las filas que contengan missing values:\n",
    "#data.dropna(inplace=True)\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar todas las columnas que contengan missing values:\n",
    "data.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?data.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejar todas las filas con al menos 4 NO missing values:\n",
    "data.dropna(thresh = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Imputación de missing values</font>\n",
    "\n",
    "Para imputar missing values usaremos el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html#pandas-dataframe-fillna\">pandas.DataFrame.fillna</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando una constante general:\n",
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {\"madrid\":[1,2,3], \"paris\":3, \"berlin\":\"alemania\"}\n",
    "diccionario[\"paris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando una constante diferente por cada columna:\n",
    "data.fillna({'var3': 0, 'var4': 0, 'var5': 'tc', 'var6': 30.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando el valor medio de cada columna (solo para\n",
    "# atributos numéricos):\n",
    "data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1,2,3]\n",
    "tupla = (1,2,3)\n",
    "diccionario = {'spain':'madrid', 'france':'paris',\n",
    "               0:'berlin' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario['spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['var5'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['var5'].mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?data.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values con la el valor medio de cada columna\n",
    "# (para atributos numéricos) y con la moda de cada columna (para atributos\n",
    "# categóricos):\n",
    "data.fillna({'var4': data['var4'].median(), 'var3': data['var3'].mean(),\n",
    "             'var5': data['var5'].mode().iloc[0], 'var6': data['var6'].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Detección de outliers</font>\n",
    "\n",
    "Usaremos el conjunto de datos *labor* para ilustrar el proceso de detección y filtrado de outliers (o \"valores atípicos\"). En las siguientes celdas cargamos los datos y realizamos un preprocesamiento para simplificar el conjunto de datos (solo conservamos los atributos numéricos e imputamos los missing values con la media del atributo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor:\n",
    "data = pd.read_csv(\"Datasets/labor.csv\", na_values = [\"?\"], sep = \",\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantener solo los atributos numéricos:\n",
    "data = data.loc[:, data.dtypes != object]\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas de los datos:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values con la media, in place:\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda detecta como outliers a aquellos valores cuya distancia a la media es mayor que 3 veces la desviación estándar. Finalmente muestra la lista de todos los atributos que tienen algún outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.abs(data - data.mean()) > 3.0*data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "is_outlier = np.abs(data - data.mean()) > 3.0*data.std()\n",
    "is_outlier.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier[\"holidays\"].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers:\n",
    "import numpy as np\n",
    "is_outlier = np.abs(data - data.mean()) > 3.0*data.std()\n",
    "for var in data.columns:\n",
    "    print(var, is_outlier[var].any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma de verlo:\n",
    "import numpy as np\n",
    "\n",
    "separacion = np.abs(data - data.mean()) / data.std()\n",
    "is_outlier = separacion > 3\n",
    "data[is_outlier.any(axis=1)]\n",
    "separacion[is_outlier.any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora miremos con cuidado a las variables *hours*, *stby_pay*, *shift_diff* y *holidays*, todas con outliers. Para cada una de ellas sacaremos por pantalla la media y desviación estándar, mostraremos un histograma, y sacaremos la lista de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'hours'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'stby_pay'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'shift_diff'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'holidays'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Filtrado de outliers</font>\n",
    "\n",
    "La opción más sencilla es eliminar todas las filas que contienen algún valor atípico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de todas las filas que contienen algún valor atípico:\n",
    "data[~is_outlier.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Reemplazamiento de valores atípicos</font>\n",
    "\n",
    "Otra opción es reemplazar los valores atípicos por otro valor. Una buena opción es la media más / menos tres veces la desviación estándar. En la celda siguiente hacemos esto para la variable *hours*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'holidays'\n",
    "var_mean = data[var].mean()\n",
    "var_std  = data[var].std()\n",
    "print(var_mean, var_std, \"\\n\")\n",
    "print(data[is_outlier[var]])\n",
    "plt.figure()\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "var_mean = data[var].mean()\n",
    "var_std  = data[var].std()\n",
    "data[var][is_outlier[var]] = data[var][is_outlier[var]].clip(var_mean-3*var_std,\n",
    "                                                             var_mean+3*var_std)\n",
    "print(data[is_outlier[var]])\n",
    "plt.figure()\n",
    "data[var].hist()\n",
    "plt.title(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11.094339622641511 + 3*1.2139685648936156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Eliminación de atributos constantes</font>\n",
    "\n",
    "Un atributo cuyo valor es constante para todas las instancias es completamente inútil para cualquier algoritmo de aprendizaje.\n",
    "\n",
    "Volvamos a cargar el conjunto de datos *labor* y lo manipularemos un poco para que tenga atributos constantes e ilustrar este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor:\n",
    "data = pd.read_csv(\"datasets/labor.csv\", na_values = [\"?\"], sep = \",\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pondremos valores constantes a los atributos cola y educ_allw:\n",
    "data[\"cola\"] = 'tc'\n",
    "data[\"educ_allw\"] = 'yes'\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de valores únicos excluyendo NaN:\n",
    "data.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos con un solo valor:\n",
    "data.apply(pd.Series.nunique) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de las columnas cola y educ_allw:\n",
    "del data[\"cola\"]\n",
    "del data[\"educ_allw\"]\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Detección de duplicados</font>\n",
    "\n",
    "Podemos usar el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html#pandas-dataframe-duplicated\">pandas.DataFrame.duplicated</a> para detectar filas duplicadas en los datos, y el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html#pandas-dataframe-drop-duplicates\">pandas.DataFrame.drop_duplicates</a> para eliminar todos los duplicados.\n",
    "\n",
    "Cargaremos de nuevo la base de datos *labor* y la manipularemos un poco para que ahora tenga filas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor, mantendremos solo un subconjunto de los atributos:\n",
    "data = pd.read_csv(\"Datasets/labor.csv\", na_values = [\"?\"], sep = \",\")\n",
    "keep_cols = [\"pension\", \"educ_allw\", \"holidays\", \"vacation\"]\n",
    "data = data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = data.iloc[-1:0:-1]\n",
    "aux = data\n",
    "aux[aux.duplicated(keep = 'first')].sort_values(by = [\"pension\", \"educ_allw\",\n",
    "                                   \"holidays\", \"vacation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?data.duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de duplicados:\n",
    "data[data.duplicated(keep = False)].sort_values(by = [\"pension\", \"educ_allw\",\n",
    "                                                      \"holidays\", \"vacation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de duplicados:\n",
    "data_nodup = data.drop_duplicates()\n",
    "data_nodup.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Otras inconsistencias</font>\n",
    "\n",
    "Podemos detectar muchos más problemas mirando detenidamente a los datos. Algunos ejemplos:\n",
    "\n",
    "- ¿Las fechas parecen fechas?\n",
    "- ¿La edad de una persona está en un rango razonable? \n",
    "- ¿Hay valores \"extraños\" que deberían ser considerados como NaN?\n",
    "- ¿Hay atributos numéricos que deberían ser considerados categóricos?\n",
    "- ¿Hay valores diferentes que se refieren a la misma cosa?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Ejercicio</font>\n",
    "\n",
    "Carga la base de datos *loan*, explora los datos usando los análisis previos e intenta responder a las cuestiones siguientes:\n",
    "\n",
    "- ¿Hay missing values? Si es así, filtra o imputa estos valores usando la estrategia más apropiada. \n",
    "- ¿Hay outliers? \n",
    "- ¿Hay atributos constantes o instancias duplicadas?\n",
    "- ¿Hay alguna otra inconsistencia en los datos que debería ser corregida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
