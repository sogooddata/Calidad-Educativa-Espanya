{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"height:40px\"><h2 style=\"align-content:center;padding:10px;color:white;background-color:#A4644E;float:left;margin-top:0px\">Máster en Big Data y Data Science</h2>\n",
    "<h2  style=\"align-content:center;padding:10px;color:white;background-color:#E0A030;float:left;margin-top:0px;\">Fundamentos de análisis de datos</h2></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión\n",
    "En este ejercicio vamos a ver el funcionamiento básico de los árboles de decisión. Haremos algunos ejemplos en problemas en 2D para su visualización y otros problemas para ver sus capacidades y debilidades. Al final del ejercicio serás capaz de:\n",
    "<ul>\n",
    "<li>Describir el mecanismo utilizado por los árboles de decisión para construir modelos reduciendo la impureza de los datos</li>\n",
    "<li>Reconocer el aspecto de las fronteras de decisión de los árboles</li>\n",
    "<li>Comprobar cómo varía la estructura del árbol modificando el número de ejemplo mínimos que cae en cada hoja</li>\n",
    "<li>Medir tiempo de entrenamiento de los árboles con respecto al número de ejemplos</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos los imports necesarios\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import numpy.matlib as matl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Cómo encontrar la mejor división en los datos: Crieterio de Gini\n",
    "Vamos a implamentar una serie de funciones para encontrar la mejor división de los datos usando el criterio de Gini. Para ello vamos a implementar rtes funciones.\n",
    "\n",
    "##### Función de impureza\n",
    "Vamos a implementar una función para la impureza de Gini que se usa en los árboles CART:\n",
    "\n",
    "$$\n",
    "i(t) = \\sum_{i=1}^{M} f_{i} (1-f_{i})\n",
    "$$\n",
    "\n",
    "La función recibe una lista con el histograma con el número de ejemplos para cada clase. Debe devolver su impureza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impurityGini: Calcula la impureza de Gini\n",
    "#    Entrada: \n",
    "#      -fs: lista/vector con el histograma con el número de ejemplos\n",
    "#           para cada clase.\n",
    "#    Salida:\n",
    "#      -i(t): Impureza\n",
    "def impurityGini(fs):\n",
    "    fs_norm = fs/float(sum(fs))\n",
    "    return sum(fs_norm*(1-fs_norm))\n",
    "\n",
    "#  Implementación con bucles seria\n",
    "#  fs_norm = fs/float(sum(fs))\n",
    "#  s = 0\n",
    "#  for fi in fs_norm:\n",
    "#      s + = fi*(1-fi)\n",
    "#  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests función de impureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerancia = 0.000000001\n",
    "# Usando número de ejemplos. Debe devolver 0.44444444\n",
    "num_ejemplos = np.array([4.,8.])\n",
    "assert(abs(impurityGini(num_ejemplos)-4./9)<tolerancia)\n",
    "\n",
    "# Usando clases puras. Debe devolver 0\n",
    "num_ejemplos = np.array([12.,0.])\n",
    "assert(abs(impurityGini(num_ejemplos))<tolerancia)\n",
    "\n",
    "# Usando clases equilibradas. Debe devolver 0.5\n",
    "num_ejemplos = np.array([6.,6.])\n",
    "assert(abs(impurityGini(num_ejemplos)-0.5)<tolerancia)\n",
    "\n",
    "# Usando 4 clases y equilibradas. Debe devolver 0.75\n",
    "num_ejemplos = np.array([4.,4.,4.,4.])\n",
    "assert(abs(impurityGini(num_ejemplos)-0.75)<tolerancia)\n",
    "\n",
    "# Usando 4 clases deequilibradas. Debe devolver 0.5546875\n",
    "num_ejemplos = np.array([8.,0.,7.,1.])\n",
    "assert(abs(impurityGini(num_ejemplos)-0.5546875)<tolerancia)\n",
    "\n",
    "print(\"Todo OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grafica de función de impureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debe mostrar una gráfica con una parábola invertida\n",
    "fracciones = np.linspace(0,1,100)\n",
    "impurities = list(map(impurityGini,np.array(list(zip(fracciones,1-fracciones)))))\n",
    "plt.ylabel(\"impurity\")\n",
    "plt.xlabel(\"fraction of instances in class 1\")\n",
    "_ = plt.plot(fracciones, impurities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Viendo la gráfica responde a las siguientes preguntas:\n",
    "<ul>\n",
    "<li>(1) ¿En qué punto se alcanza la mayor impureza de los datos? ¿A qué distribución de clases correnpondería?</li>\n",
    "<li>(2) ¿En qué punto se alcanza la menor impureza de los datos? ¿A qué distribución de clases correnpondería?</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "<ul>\n",
    "<li>(1): Responde aquí </li>\n",
    "<li>(2): Responde aquí </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Función para calcular la reducción de impureza\n",
    "Vamos a implementar una función de variación de impureza para un nodo $t$ y división $s$ utilizado en los árboles CART:\n",
    "\n",
    "$$\n",
    "\\Delta i(t, s) = i(t) - p_L \\times i(t_L) - p_R \\times i(t_R)\n",
    "$$\n",
    "\n",
    "La función recibe una lista con los histogramas o fracción de ejemplos para cada clase para el nodo derecho e izquierdo y te devuelve la variación de impureza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impurityReduction: Calcula la reducción de impureza de Gini a partir\n",
    "#      de las distribuciones de ejemplos en el nodo derecho e izquierdo.\n",
    "#      para saber la distribución antes de la división hay que sumar\n",
    "#      fs_left y fs_right\n",
    "#    Entrada: \n",
    "#      -fs_left:  lista/vector con el histograma de ejemplos\n",
    "#                 para cada clase que van al nodo izq tras la división.\n",
    "#      -fs_right: lista/vector con el histograma o fraccion de ejemplos\n",
    "#                 para cada clase que van al nodo dcho tras la división.\n",
    "#    Salida:\n",
    "#      -Delta i(t): Variación de la impureza\n",
    "def impurityReduction(fs_left, fs_right):\n",
    "    it = impurityGini(fs_left+fs_right)\n",
    "    iL = impurityGini(fs_left) \n",
    "    iR = impurityGini(fs_right)\n",
    "    sL = sum(fs_left)\n",
    "    sR = sum(fs_right)\n",
    "    return it - iL*sL/(sL+sR) - iR*sR/(sL+sR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests función impurityReduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerancia = 0.000000001\n",
    "\n",
    "#Debe devolver 0.5\n",
    "lf = np.array([4.,0.])\n",
    "rg = np.array([0.,4.])\n",
    "assert(abs(impurityReduction(lf,rg)-0.5)<tolerancia)\n",
    "\n",
    "#Debe devolver 0.11111111111\n",
    "lf = np.array([4.,0.])\n",
    "rg = np.array([4.,4.])\n",
    "assert(abs(impurityReduction(lf,rg)-0.1111111111111)<tolerancia)\n",
    "\n",
    "#Debe devolver 0\n",
    "lf = np.array([4.,4.])\n",
    "rg = np.array([4.,4.])\n",
    "assert(abs(impurityReduction(lf,rg))<tolerancia)\n",
    "\n",
    "print(\"Todas OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Viendo los valores de las pruebas responde a las siguientes preguntas:\n",
    "<ul>\n",
    "<li>(3) ¿Qué división se hace cuando se reduce 0'5 la impureza (caso 1 arriba)? ¿Qué distribución de clases tienen antes de la división?¿Y después?</li>\n",
    "<li>(4) ¿Qué división se hace cuando no se reduce la impureza (caso 3 arriba)? ¿Qué distribución de clases tienen antes de la división?¿Y después?</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "<ul>\n",
    "<li>(3): Aquí tu respuesta</li>\n",
    "<li>(4): Aquí tu respuesta</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Función para calcular la mejor partición a partir de un conjunto de datos\n",
    "Esta función debe recorrer todos los atributos (columnas) de los datos y calcular todas las posibles divisiones recorriendo valores de los ejemplos ordenados (filas).\n",
    "\n",
    "La función recibe una matriz X con los datos y un vector y con las clases para cada dato donde la primera clase es la 0, la segunda la 1, etc. Debe devolver el atributo donde se ha encontrado la mejor división y el umbral de corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestSplit: Busca la mejor partición de los datos usando el criterio de Gini\n",
    "#\n",
    "#    Entrada: \n",
    "#     - X: Matriz de ejemplos con atributos en columnas y datos en filas\n",
    "#      -y: Vector con las clases de cada ejemplo. Debe ser de la misma \n",
    "#          longitud que el numero de filas de X\n",
    "#    Salida:\n",
    "#      -atributo de la división \n",
    "#      -valor para el corte\n",
    "def findBestSplit(X, y):\n",
    "    assert(X.shape[0]==len(y))\n",
    "    irmax = 0\n",
    "    for ia in range(X.shape[1]):           # Recorremos atributos\n",
    "        idx         = np.argsort(X[:,ia])      # Ordenamos los datos por el atributo de índice ia\n",
    "        attr_sorted = X[idx,ia]\n",
    "        y_sorted    = y[idx]\n",
    "        hist_left   = np.array([0.0, 0.0])     # Inic num. ejemplos en hoja izq -> ninguno\n",
    "        hist_right  = np.bincount(y)           # Inic. num. ejemplos en hoja dcha -> todos\n",
    "        for isplit in range(X.shape[0]-1): # Recorremos las posibles divisiones\n",
    "            hist_left[y_sorted[isplit]]  += 1.0    # Actualizamos histogramas de num. ejemplos añadiendo a hoja izq\n",
    "            hist_right[y_sorted[isplit]] -= 1.0    #                                        y eliminando de la dcha\n",
    "            if attr_sorted[isplit] != attr_sorted[isplit+1]: # Si este dato y el siguiente son distintos se calcula\n",
    "                ir = impurityReduction(hist_left, hist_right)    # la reducción de impureza\n",
    "                if ir > irmax:                                   # Si mejoramos guardamos el atrib. y umbral corte\n",
    "                    irmax = ir\n",
    "                    iatt_best = ia\n",
    "                    threshold_best = attr_sorted[isplit] + (attr_sorted[isplit+1] - attr_sorted[isplit])/2.\n",
    "            \n",
    "    return iatt_best, threshold_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo del ppt\n",
    "X = np.array([[1, 2],[1, 5],[2, 1],[2, 3],\n",
    "              [2, 4],[3, 2],[3, 4],[4, 1],\n",
    "              [4, 2],[4, 3],[4, 5],[5, 2]])\n",
    "clase = np.array([0,1,0,0,1,1,1,1,0,1,1,1])\n",
    "\n",
    "# Debe devolver (1, 3.5)\n",
    "findBestSplit(X,clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Viendo el funcionamiento de la función:\n",
    "<ul>\n",
    "<li> (5) Describe cómo es el prodecimiento para buscar la mejor división en los árboles de decisión</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "<ul>\n",
    "<li>(5): Aquí tu respuesta</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Conjuntos en 2D para el anáilisis visual de las fronteras de decisión y cómo cambian con algunos parámetros\n",
    "\n",
    "##### Funciones auxiliares\n",
    "Antes definiremos algunas funciones (autores Luis Lago y Manuel Sanchez Montañes) que usaremos a lo largo de la práctica. La primera, *createDataSet*, es para crear los problemas, siempre con dos clases y en dos dimensiones. Sus argumentos son:\n",
    "\n",
    "- *n*, número de patrones en el problema\n",
    "\n",
    "- *model*, tipo de modelo para la frontera que separa las clases, puede ser 'linear', 'square' o 'sine'\n",
    "\n",
    "- *ymargin*, margen de separación entre las dos clases, cuanto mayor es *ymargin* más separadas están las clases, valores negativos implican solape entre las clases\n",
    "\n",
    "- *noise*, introduce un ruido gausiano a la x e y\n",
    "\n",
    "- *output_boundary*, Si vale True la función devuelve la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(n,model,ymargin,noise=None,output_boundary=False):\n",
    "    x = np.random.rand(n,1)*2.0*np.pi\n",
    "    xbnd = np.linspace(0,2.0*np.pi,100)\n",
    "\n",
    "    if model == 'sine':\n",
    "        y = (np.random.rand(n,1) - 0.5)*2.2\n",
    "        c = y > np.sin(x)\n",
    "        ybnd = np.sin(xbnd)\n",
    "    elif model == 'linear':\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    elif model == 'square':\n",
    "        y = np.random.rand(n,1)*4.0*np.pi*np.pi\n",
    "        c = y > x*x\n",
    "        ybnd = xbnd*xbnd\n",
    "    else:\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    \n",
    "    y[c == True] = y[c == True] + ymargin\n",
    "    y[c == False] = y[c == False] - ymargin\n",
    "    if noise is not None:\n",
    "        y = y + noise * np.random.randn(n,1)\n",
    "        x = x + noise * np.random.randn(n,1)\n",
    "\n",
    "    if output_boundary == True:\n",
    "        return np.matlib.matrix(x), np.matlib.matrix(y), np.matlib.matrix(c*1), xbnd, ybnd\n",
    "    else:\n",
    "        return np.matlib.matrix(x), np.matlib.matrix(y), np.matlib.matrix(c*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *plotModel* la usaremos para dibujar el resultado de un clasificador sobre el conjunto de datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos, si se pasa None, entonces considera que x e y son la frontera real de decisión y la muestra con plot\n",
    "\n",
    "- *clf*, el clasificador\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModel(x,y,clase,clf,title):\n",
    "    x_min, x_max = x.min() - .2, x.max() + .2\n",
    "    y_min, y_max = y.min() - .2, y.max() + .2\n",
    "    hx = (x_max - x_min)/100.\n",
    "    hy = (y_max - y_min)/100.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    z = z.reshape(xx.shape)\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    #ax = plt.subplot(1, 1, 1)\n",
    "    plt.contourf(xx, yy, z, cmap=cm, alpha=.8)\n",
    "    plt.contour(xx, yy, z, [0.5], linewidths=[2], colors=['k'])\n",
    "\n",
    "    if clase is not None:\n",
    "        plt.scatter([x[clase==0]], [y[clase==0]], c='#FF0000')\n",
    "        plt.scatter([x[clase==1]], [y[clase==1]], c='#0000FF')\n",
    "    else:\n",
    "        plt.plot(x,y,'g', linewidth=3)\n",
    "        \n",
    "    plt.gca().set_xlim(xx.min(), xx.max())\n",
    "    plt.gca().set_ylim(yy.min(), yy.max())\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función, *plotData*, la usaremos para dibujar los datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos\n",
    "\n",
    "- *style0*, estilo con el que pintamos los puntos de la clase 0\n",
    "\n",
    "- *style1*, estilo con el que pintamos los puntos de la clase 1\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x,y,c,style0,style1,title):\n",
    "    plt.plot(x[c==0],y[c==0],style0)\n",
    "    plt.plot(x[c==1],y[c==1],style1)\n",
    "    plt.grid(True)\n",
    "    plt.axis([x.min()-0.2, x.max()+0.2, y.min()-0.2, y.max()+0.2])\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el árbol\n",
    "Se entrena un árbol usando los datos del ppt y visualizamos su estructura y la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos\n",
    "X = np.array([[1, 2],[1, 5],[2, 1],[2, 3],\n",
    "              [2, 4],[3, 2],[3, 4],[4, 1],\n",
    "              [4, 2],[4, 3],[4, 5],[5, 2]])\n",
    "clase = np.array([0,1,0,0,1,1,1,1,0,1,1,1])\n",
    "\n",
    "# Declaración del clasificador:\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", min_samples_leaf=1, max_depth=None)   # Rellenar\n",
    "\n",
    "# Entrenar el clasificador\n",
    "clf.fit(X, clase)                                       # Rellenar\n",
    "\n",
    "# Clasificar datos\n",
    "score_train = clf.score(X, clase)\n",
    "\n",
    "# Frontera de decisión:\n",
    "plt.figure(figsize=(6,6))\n",
    "plotModel(X[:,0],X[:,1],clase,clf,\"Training, score = %f\" % (score_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "#import pydot2\n",
    "from IPython.display import Image\n",
    "from subprocess import call\n",
    "\n",
    "#Exportar a formato dot\n",
    "file_name='tree.out'\n",
    "tree.export_graphviz(clf, out_file=file_name, feature_names = ['x0','x1'])\n",
    "# Ejecuta un comando en la terminal. Esta línea es solo valida para linux y dot debe estar instalado\n",
    "call(['dot', '-Tpng', file_name, '-o' 'tree.png'])\n",
    "Image(filename='tree.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "<ul>\n",
    "<li> (6) Modifica parámetros de construcción del árbol para obtener un árbol más compacto que elimine el cuadrado rojo de abajo a la derecha. Indica qué parámetro has modificado y explica las diferencias que creeís que hay entre los árboles que usan prepoda con max_depth o con min_samples_leaf.</li>\n",
    "</ul>\n",
    "</div>\n",
    "<p></p>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "<ul>\n",
    "<li>(6): Aquí tu respuesta</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo con funciones más complejas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ejecuta las dos celdas siguientes utilizando 0 ruido en los datos y un ruido de 0.3. Después prueba con min_samples_leaf 1 y 10 para cada uno de los niveles de ruido y rellena el acierto en test y train en la siguiente tabla:<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(7) Respuestas:\n",
    " <table>\n",
    "  <tr>\n",
    "    <td>Acierto train/test</td>\n",
    "    <td>min_samples_leaf=1</td>\n",
    "    <td>min_samples_leaf=10</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>noise=0</td>\n",
    "    <td> </td>\n",
    "    <td> </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>noise=0.3</td>\n",
    "    <td> </td>\n",
    "    <td> </td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem data:\n",
    "np.random.seed(11)\n",
    "n = 300\n",
    "model = 'sine'\n",
    "ymargin = 0.\n",
    "noise = 0.0                             # <========= Modifica este valor 0 ó 0.3\n",
    "x, y, clase, xbnd, ybnd = createDataSet(n, model, ymargin, noise, True)\n",
    "xtest, ytest, clasetest = createDataSet(n*10, model, ymargin, noise)\n",
    "\n",
    "# Plots:\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plotData(x,y,clase,'ro','bo',\"Training data\")\n",
    "plt.subplot(122)\n",
    "plotData(xtest,ytest,clasetest,'ro','bo',\"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del clasificador:\n",
    "clf = tree.DecisionTreeClassifier(min_samples_leaf=1)     # <========= Modifica este valor 1 ó 10\n",
    "clf.fit(np.concatenate((x, y), axis = 1), np.ravel(clase))  \n",
    "\n",
    "# Calculo del acierto en los conjuntos de entrenamiento y test:\n",
    "score_train = clf.score(np.concatenate((x, y), axis = 1), np.ravel(clase))\n",
    "print(\"Score train = %f\" % (score_train))\n",
    "score_test = clf.score(np.concatenate((xtest, ytest), axis = 1), np.ravel(clasetest))\n",
    "print(\"Score test = %f\" % (score_test))\n",
    "\n",
    "# Gráficas:\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plotModel(x,y,clase,clf,\"Training, score = %f\" % (score_train))\n",
    "plt.subplot(122)\n",
    "plotModel(xbnd,ybnd,None,clf,\"Test, score = %f\" % (score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a realizar un bucle para calcular el acierto del árbol en train y test con respecto al parámetro min_samples_leaf usando ruido (noise=0.3). Entrena árboles usando min_samples_leaf de 1 a 30. Muestra los datos en forma de gráfica usando matlibplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins_samples = range(1,30)\n",
    "scores_tr = np.array([0.]*len(mins_samples))\n",
    "scores_ts = np.array([0.]*len(mins_samples))\n",
    "i=0\n",
    "for m in mins_samples:\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_leaf=m)\n",
    "    clf.fit(np.concatenate((x, y), axis = 1), np.ravel(clase))  \n",
    "    # Calculo del acierto en los conjuntos de entrenamiento y test:\n",
    "    scores_tr[i] = clf.score(np.concatenate((x, y), axis = 1), np.ravel(clase))\n",
    "    scores_ts[i] = clf.score(np.concatenate((xtest, ytest), axis = 1), np.ravel(clasetest))\n",
    "    i = i + 1\n",
    "\n",
    "plt.plot(mins_samples, scores_tr, label='train')\n",
    "plt.plot(mins_samples, scores_ts, label='test')\n",
    "plt.xlabel(\"Min ejemplos por hoja\")\n",
    "plt.ylabel(\"Acierto\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla y la gráfica (si la has hecho) describe qué valores de min_leaf os dan mejores resultados dependiendo del ruido introducido en los datos y da una justificación a los resultados <br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(8) Respuesta: \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Tiempos de entrenamiento y test de los árboles de decisión\n",
    "Vamos a medir tiempos de entrenamiento y clasificación de árboles de decisión y a compararlos con los tiempos de las SVMs. Probaremos a entrenar los modelos con 300 datos y con 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skpp\n",
    "import timeit\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n_executions = 1\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "# Dividimos train/test\n",
    "n_train = 300                                      # <================== Modificar 300 o 600\n",
    "perm = np.random.permutation(dfP.shape[0])\n",
    "indices_train = perm[0:n_train]\n",
    "indices_test  = perm[n_train:]\n",
    "\n",
    "    \n",
    "#clf = SVC(C=10.0, kernel='linear', degree=1.0, coef0=1.0, gamma=0.1) # <================== Modificar DT o SVM\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Tiempo de entrenamiento\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):    # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    clf.fit(dfP.values[indices_train,:-1],dfP.values[indices_train,-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "print(\"Tiempo de entrenamiento con %d ejemplos: %f s.\" % (len(indices_train),(toc - tic)/n_executions))\n",
    "\n",
    "n_executions = 1000\n",
    "\n",
    "# Tiempo de clasificacion\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):   # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    _ = clf.predict(dfP.values[indices_test,:-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "factor = 1000000.\n",
    "print(\"Tiempo de clasificar %g ejemplos: %f s.\" % (factor, factor*(toc - tic)/n_executions/len(indices_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Se debe ejecutar la celda de arriba utilizando árboles o SVMs para medir tiempos de entrenamiento y de clasificación. Hazlo usando 300 datos de entrenamiento y 600. A continuación se debe rellenar los tiempos en la siguiente tabla:<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(9) Respuestas:\n",
    " <table>\n",
    "  <tr>\n",
    "    <td>Tiempos (s) train</td>\n",
    "    <td>Árbol</td>\n",
    "    <td>SVM</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Entrenamiento con 300 </td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Entrenamiento con 600</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Clasificación (10^6 ejemplos)</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Clasificación (10^6 ejemplos)</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "# Compute training and testing time\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'     # <========== Se puede variar el conjunto de datos.\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#clf = SVC(C=10.0, kernel='linear', degree=1.0, coef0=1.0, gamma=0.1)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "n_steps = 10           # <========== Se puede variar el numero de paso\n",
    "n_executions = 1\n",
    "\n",
    "times_tr = np.array([timeit.default_timer()] * n_steps)\n",
    "sizes    = np.array([0] * n_steps)\n",
    "times_ts = np.array([timeit.default_timer()] * n_steps)\n",
    "sizes_ts = np.array([0] * n_steps)\n",
    "\n",
    "i = 0\n",
    "perm = np.random.permutation(dfP.shape[0])\n",
    "for fraction in  np.linspace(0.1, 0.90, num=n_steps):\n",
    "    n_train = int(len(perm)*(fraction))\n",
    "    idxTr = perm[0:n_train]  # PArticion de train\n",
    "    idxTs = perm[n_train:]   # Particion de test\n",
    "    \n",
    "    # Train\n",
    "    tic = timeit.default_timer()\n",
    "    for ie in range(n_executions):\n",
    "        clf.fit(dfP.values[idxTr,:-1],dfP.values[idxTr,-1])\n",
    "    toc = timeit.default_timer()\n",
    "    times_tr[i] = (toc - tic)/n_executions\n",
    "    sizes[i] = len(idxTr)\n",
    "    \n",
    "    # Test\n",
    "    tic = timeit.default_timer()\n",
    "    for ie in range(n_executions*10):\n",
    "        _ = clf.predict(dfP.values[idxTs,:-1])\n",
    "    toc = timeit.default_timer()\n",
    "    factor = 1000000.\n",
    "    times_ts[i] = factor*(toc - tic)/n_executions/len(idxTs)/10\n",
    "    \n",
    "    i = i + 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.grid()\n",
    "plt.subplot(121)\n",
    "plt.title('Tiempo de entrenamiento')\n",
    "plt.xlabel(\"Num. de datos de entrenamiento\")\n",
    "plt.ylabel(\"t(s)\")\n",
    "plt.plot(sizes, times_tr, 'o-', color=\"r\", label=\"DT\")\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.title('Tiempo para predecir %g instacias' %(factor))\n",
    "plt.xlabel(\"Num. de datos de entrenamiento\")\n",
    "plt.ylabel(\"t(s)\")\n",
    "plt.plot(sizes, times_ts, 'o-', color=\"r\", label=\"DT x1000\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla y la gráfica (si la has hecho) comenta los resultados.<br/>\n",
    "\n",
    "<ul>\n",
    "<li>(10) ¿Cómo varían los tiempos de entrenamiento al doblar el número de datos de entrenamiento? ¿Y los tiempos de clasificación?</li>\n",
    "<li>(11): Explica los resultados</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuesta:\n",
    "\n",
    "<ul>\n",
    "<li>(10): </li>\n",
    "<li>(11): </li>\n",
    "</ul></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
